{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA GENERATION USING WEB SCRAPPING**"
      ],
      "metadata": {
        "id": "9gkmVRXmF25w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Proxy URL"
      ],
      "metadata": {
        "id": "z5uPF54Znpa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "API_KEY = '24ecd7ca-6d06-453b-a51d-e3b17acdc624'\n",
        "def get_scrapeops_url(url):\n",
        "    payload = {'api_key': API_KEY, 'url': url,'bypass': 'cloudflare'}\n",
        "    proxy_url = 'https://api.webscraping.ai/html?' + urllib.parse.urlencode(payload)\n",
        "    return proxy_url"
      ],
      "metadata": {
        "id": "MfyDqhiLjv1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get all Ad_listing link into an array"
      ],
      "metadata": {
        "id": "ExhFN7RGnuRi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gHrFszWcbBX",
        "outputId": "1c300f72-ba39-46ad-94af-cd9ced6e32e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n",
            "Failed to fetch the page: 200\n"
          ]
        }
      ],
      "source": [
        "from requests.sessions import should_bypass_proxies\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Replace the URL below with the specific Locanto page you want to scrape\n",
        "url = 'https://bangalore.locanto.me/Women-Seeking-Men/202/'\n",
        "\n",
        "# Set a custom User-Agent header\n",
        "user_agents_list = [\n",
        "    'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148',\n",
        "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36',\n",
        "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'\n",
        "]\n",
        "\n",
        "# Send a GET request to the URL with the custom headers\n",
        "response = requests.get(get_scrapeops_url(url),headers={'User-Agent': random.choice(user_agents_list)})\n",
        "print(response)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "\n",
        "    # Find all listings on the page\n",
        "    ads = soup.find_all(\"div\", attrs={\"class\": [\"textHeader\"]})\n",
        "\n",
        "\n",
        "# create a list to store all of the URLs from the\n",
        "ad_links = []\n",
        "for ad in ads:\n",
        "  # parse the link from the ad\n",
        "  link = ad.find_all(\"a\", {\"class\": \"bp_ad__title_link js-bp_ad_title_link\"})\n",
        "  # add the link to the list\n",
        "  for l in link:\n",
        "    ad_links.append(l[\"href\"])\n",
        "\n",
        "else:\n",
        "    print('Failed to fetch the page:', response.status_code)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(ad_links))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0etcnYVxTc38",
        "outputId": "4e77dc51-616e-447a-d76a-da581aea10df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   Iterate each ad listing retrieve the description ,title,age ,date\n",
        "2.  Create Dataframe\n",
        "\n"
      ],
      "metadata": {
        "id": "BlYqyZXQnYWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a dataframe to store our results\n",
        "df = pd.DataFrame(columns=[\"Title\", \"Age\", \"description\", \"date_posted\",\n",
        "                            \"url\"])\n",
        "\n",
        "for advert in (ad_links):\n",
        "  # grab webpage information & transform with BS\n",
        "  response = requests.get(get_scrapeops_url(advert),headers={'User-Agent': random.choice(user_agents_list)})\n",
        "  print(response)\n",
        "  soup = BeautifulSoup(response.text, \"lxml\")\n",
        "\n",
        "  # get  title\n",
        "  try:\n",
        "      title = soup.find(\"span\", attrs={\"class\": [\"header-text\"]}).text\n",
        "  except AttributeError:\n",
        "      title = \"\"\n",
        "\n",
        "  # get age\n",
        "  try:\n",
        "      age = soup.find(\"span\", attrs={\"class\": [\"header-age\"]}).text\n",
        "  except AttributeError:\n",
        "      age = \"\"\n",
        "\n",
        "  # get date posted\n",
        "  try:\n",
        "      date_posted = soup.find(\"div\", attrs={\"class\": [\"posting_info\"]}).text\n",
        "  except (AttributeError, TypeError):\n",
        "      date_posted = \"\"\n",
        "\n",
        "  # get ad description\n",
        "  try:\n",
        "      description = soup.find(\"div\", attrs={\"itemprop\": \"description\"}).text\n",
        "  except AttributeError:\n",
        "      description = \"\"\n",
        "\n",
        "  # get the ad city\n",
        "  #try:\n",
        "      #address = soup.find(\"span\", attrs={\"itemprop\": \"address\"}).text\n",
        "  #except AttributeError:\n",
        "      #address = \"\"\n",
        "\n",
        "  # apend information to the dataframe\n",
        "  df = df.append({\n",
        "       \"Title\": title,\n",
        "       \"Age\": age,\n",
        "       \"description\": description,\n",
        "       \"date_posted\": date_posted,\n",
        "       \"url\": advert},\n",
        "      ignore_index=True\n",
        "  )\n",
        "print(df)\n",
        "# save the final dataframe to a csv file\n",
        "df.to_csv(\"HumanTrafficking_Textual_dataset.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P12mGWL8dvkD",
        "outputId": "cb19fba1-b39c-4efa-a7f4-7844f1398204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [502]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [502]>\n",
            "<Response [502]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "<Response [200]>\n",
            "                                                 Title Age  \\\n",
            "0    CALL GIRLS IN RIYA 24X7 HOT&SEXY BEST HOUSEWIF...  21   \n",
            "1    NO ADVANCE. OUT CALL DOOR STEP INDEPENDENT CAL...  21   \n",
            "2    CALL GIRLS IN JP NAGAR HOT&SEXY INDEPENDENT GI...  21   \n",
            "3               Sneha independent kannada girl call me  21   \n",
            "4                                                            \n",
            "..                                                 ...  ..   \n",
            "96                                                           \n",
            "97                                                           \n",
            "98                     I'm vidya (Hand cash) call girl  23   \n",
            "99   Hot Kannada Telugu tamil college girls South n...  23   \n",
            "100              Hi I am Preethi independent call girl  22   \n",
            "\n",
            "                                           description  \\\n",
            "0    \\n\\t\\t\\t\\n\\n\\tHyy guys\\nhttps://wa.me/+9193585...   \n",
            "1    \\n\\t\\t\\t\\n\\n\\tNO ADVANCE DIRECT PAYMENT HOTEL ...   \n",
            "2    \\n\\t\\t\\t\\n\\n\\tPROFESSIONAL ESCORT SERVICES\\n\\n...   \n",
            "3    \\n\\t\\t\\t\\n\\n\\tSneha 8861589137\\n Hand cash/onl...   \n",
            "4                                                        \n",
            "..                                                 ...   \n",
            "96                                                       \n",
            "97                                                       \n",
            "98   \\n\\t\\t\\t\\n\\n\\tHi am VIDYA staying alone. call ...   \n",
            "99   \\n\\t\\t\\t\\n\\n\\tCall Or WhatsApp mr Dharma 90362...   \n",
            "100  \\n\\t\\t\\t\\n\\n\\tIndependence college girl availa...   \n",
            "\n",
            "                                           date_posted  \\\n",
            "0    \\nPosted\\n\\t\\t\\t\\t\\tless than a week ago\\n\\t\\t...   \n",
            "1           \\nPosted\\n\\t\\t\\t\\t\\tone hour ago\\n\\t\\t\\t\\t   \n",
            "2          \\nPosted\\n\\t\\t\\t\\t\\ttwo hours ago\\n\\t\\t\\t\\t   \n",
            "3    \\nPosted\\n\\t\\t\\t\\t\\tless than a month ago\\n\\t\\...   \n",
            "4                                                        \n",
            "..                                                 ...   \n",
            "96                                                       \n",
            "97                                                       \n",
            "98   \\nPosted\\n\\t\\t\\t\\t\\tless than a month ago\\n\\t\\...   \n",
            "99            \\nPosted\\n\\t\\t\\t\\t\\ta week ago\\n\\t\\t\\t\\t   \n",
            "100             \\nPosted\\n\\t\\t\\t\\t\\tjust now\\n\\t\\t\\t\\t   \n",
            "\n",
            "                                                   url  \n",
            "0    https://howrah.locanto.me/ID_6576170707/CALL-G...  \n",
            "1    https://bangalore.locanto.me/ID_6581184903/NO-...  \n",
            "2    https://bangalore.locanto.me/ID_6581167848/CAL...  \n",
            "3    https://bangalore.locanto.me/ID_6556793452/Sne...  \n",
            "4    https://bangalore.locanto.me/ID_6581186318/CAL...  \n",
            "..                                                 ...  \n",
            "96   https://bangalore.locanto.me/ID_6525180138/Hi-...  \n",
            "97   https://bangalore.locanto.me/ID_6581184353/CAL...  \n",
            "98   https://bangalore.locanto.me/ID_6494236858/I-m...  \n",
            "99   https://bangalore.locanto.me/ID_6570934522/Hot...  \n",
            "100  https://bangalore.locanto.me/ID_6581190914/Hi-...  \n",
            "\n",
            "[101 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fyOps7A3kjHe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}